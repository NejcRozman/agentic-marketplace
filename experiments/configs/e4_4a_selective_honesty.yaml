# E4.4a: Selective Honesty - Byzantine Robustness Test
# Research Question: RQ4 - Byzantine Robustness
# Description: 1 adversarial provider (11%) honest on easy tasks, cheating on hard tasks vs 8 honest providers

experiment:
  id: "e4_4a_selective_honesty"
  name: "Selective Honesty (11% attackers)"
  description: |
    Tests if adversaries can maintain reputation by being honest on easy/cheap tasks while
    cheating on difficult/expensive tasks. Byzantine provider delivers high quality on
    simple services (1-2 PDFs) but low quality on complex services (3+ PDFs).
    Strategy: Maintain acceptable average reputation while maximizing profit by skipping expensive work.
    1 Byzantine provider vs 8 honest providers over 50 auctions with VARIED service complexity.
  research_question: "RQ4"
  duration_timeout: 21600  # Maximum 6 hours for entire experiment
  
blockchain:
  network: "anvil"
  rpc_url: "http://localhost:8545"
  fork_network: "sepolia"  # Fork from Sepolia to get ERC-8004 contracts
  infura_key_env: "INFURA_API_KEY"  # Read from environment
  
  contracts:
    # Addresses of contracts (deployed by experiment or pre-existing)
    reverse_auction: null  # null = deploy new
    identity_registry: "0x8004a6090Cd10A7288092483047B097295Fb8847"  # Sepolia ERC-8004
    reputation_registry: "0x8004B8FD1A363aa02fDC07635C0c5F94f6Af5B7E"  # Sepolia ERC-8004
    payment_token: null  # null = deploy mock USDC
    
  accounts:
    main_account: "${BLOCKCHAIN_PRIVATE_KEY}"
    deployer: "${BLOCKCHAIN_PRIVATE_KEY}"
    consumer: "${BLOCKCHAIN_CONSUMER_PRIVATE_KEY}"
    providers:
      - "${BLOCKCHAIN_PRIVATE_KEY}"  # Only need 1 key, experiment runner generates others
    
    # Funding configuration for consumer account
    consumer_funding:
      eth_amount: 2000000000000000000  # 2 ETH in wei
      usdc_amount: 2000000000  # 2000 USDC (6 decimals)

agents:
  consumer:
    count: 1
    agent_id: null  # null = register new agent
    private_key: null  # null = use blockchain.accounts.consumer
    
    config:
      check_interval: 5  # Check blockchain every 5 seconds
      max_budget: 100000000  # 100 USDC per auction (with 6 decimals)
      auction_duration: 60  # 1 minute per auction
      reputation_weight: 25  # 0-100: weight of reputation vs price (25 = 25% reputation, 75% price)
      
    behavior:
      pdf_directory: "utils/files"  # Use existing test PDFs
      service_selection: "random"  # Random selection to vary complexity
      service_complexity: "varied"  # Mixed easy/medium/hard (if implemented)
      auto_create_auction: true  # Create auction immediately on start
      num_auctions: 50  # Create 50 sequential auctions
      auto_monitor: true  # Monitor auction automatically
      inter_auction_delay: 5  # Wait 5 seconds between auctions
      eligible_per_auction: 9  # All 9 providers eligible per auction
      
      # Service Complexity Variation (IMPLEMENTATION REQUIRED):
      # Currently using 3 PDFs in utils/files/ (1.txt, 2.txt, 3.txt)
      # Ideal implementation would vary:
      # - Easy: 1 PDF (short, simple questions)
      # - Medium: 2 PDFs (moderate length, standard questions)
      # - Hard: 3 PDFs (longer, complex synthesis questions)
      #
      # For initial experiment: Use PDF count as proxy for complexity
      # - service_selection: "random" â†’ randomly select 1, 2, or 3 PDFs per auction
      # - Byzantine strategy detects complexity from PDF count in service request
      
  providers:
    count: 9  # Total 9 providers (1 adversarial + 8 honest)
    
    # Define honest vs adversarial groups
    groups:
      - type: "honest"
        count: 8
        agent_type: "provider_agent"  # Use normal provider
        agent_ids: [null, null, null, null, null, null, null, null]  # null = register new agents
        private_keys: null  # null = experiment runner generates
        
        config:
          check_interval: 5  # Check blockchain every 5 seconds
          quality_profile: "medium"  # Standard quality
          
        behavior:
          auto_bid: true  # Automatically bid on detected auctions
          auto_execute: true  # Automatically execute won services
          auto_complete: true  # Automatically complete on blockchain
          
      - type: "adversarial"
        count: 1
        agent_type: "adversarial_provider_agent"  # Use adversarial provider
        agent_ids: [null]  # null = register new agent
        private_keys: null  # null = experiment runner generates
        
        config:
          check_interval: 5  # Check blockchain every 5 seconds
          
        behavior:
          strategy: "price_manipulation"  # Selective honesty strategy
          auto_bid: true  # Automatically bid on detected auctions
          auto_execute: true  # Execute service (quality depends on complexity)
          auto_complete: true  # Complete on blockchain to collect payment
          
          # Strategy behavior (implemented in adversarial_strategies.py):
          # - Detects service complexity from service description/PDF count
          # - Easy tasks (1-2 PDFs): Deliver high quality (use LLM properly)
          # - Hard tasks (3+ PDFs): Deliver low quality (hardcoded response)
          # - Goal: Maintain moderate reputation (~50-60) while maximizing profit
          #
          # Implementation note: Currently uses bid_multiplier=0.5 for all tasks
          # May need enhancement to vary behavior based on actual service complexity
     
experiment_flow:
  phases:
    - name: "setup"
      description: "Start Anvil, deploy contracts, register agents, mint USDC"
      
    - name: "execution"
      description: |
        Consumer creates 50 sequential auctions with VARIED service complexity.
        Byzantine provider executes selective honesty attack:
        - Easy tasks: Deliver high quality (use LLM) to maintain reputation
        - Hard tasks: Deliver low quality (hardcoded) to save costs
        - Goal: Maintain acceptable average reputation while cheating on expensive work
      
    - name: "completion"
      description: "Collect all metrics and reputation snapshots"
      
    - name: "analysis"
      description: |
        Analyze selective honesty effectiveness:
        - Quality scores by service complexity (easy vs medium vs hard)
        - Reputation trajectory (does mixing maintain stable reputation?)
        - Profitability vs honest providers (does selective cheating increase profit?)
        - Consumer detection: Correlation between task difficulty and quality
        - Win rate by service complexity
        - Key question: Is average reputation sufficient, or need per-task-type tracking?
      
metrics:
  collect:
    - "auction_details"
    - "bid_amounts"
    - "winner_selection"
    - "service_quality"
    - "service_complexity"  # Track which tasks were easy/medium/hard
    - "reputation_evolution"
    - "win_distribution"
    - "cost_analysis"
    - "timing_data"
    - "quality_by_complexity"  # Critical metric for this attack
    
  analysis:
    - "quality_scores_by_service_complexity"
    - "reputation_trajectory_selective_honesty"
    - "profitability_comparison_honest_vs_byzantine"
    - "consumer_detection_correlation"
    - "win_rate_by_complexity"
    - "attack_sustainability_analysis"
    - "average_reputation_vs_per_task_tracking"
    
  notes: |
    Implementation Requirement: Service Complexity Variation
    
    Current Setup:
    - 3 PDFs available in utils/files/ (1.txt, 2.txt, 3.txt)
    - Consumer can randomly select subset of PDFs per auction
    - PDF count serves as proxy for complexity
    
    Ideal Enhancement (Future Work):
    - Easy: 1-2 PDFs (< 50 pages), simple factual questions
    - Medium: 3-4 PDFs (50-150 pages), analytical questions
    - Hard: 5-6 PDFs (150+ pages), complex synthesis questions
    
    Byzantine Strategy Detection:
    - AdversarialBehaviorController checks service description for complexity indicators
    - Current implementation: May need to parse PDF count from service request
    - Fallback: Use bid amount as proxy (higher budget = harder task)
    
    Success Criteria:
    - If selective honesty maintains reputation: Attack succeeds (need defense)
    - If reputation drops anyway: System detects pattern and penalizes appropriately
    - Key insight: Tests whether average reputation is sufficient metric
